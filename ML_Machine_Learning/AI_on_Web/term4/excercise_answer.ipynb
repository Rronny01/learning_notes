{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWV-2HVlzVDo"
   },
   "source": [
    "# 機械学習とデータセット - 演習用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtZ8RKUIzVDp"
   },
   "source": [
    "## 目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本講義では、機械学習において必要なデータセットをいかに用意するかについて扱ってきました。  \n",
    "ここでは、ウェブスクレイピングによるデータの収集について扱っていきます。  \n",
    "演習においては、次のウェブスクレイピングの練習を目的として構築されたサイトを用います。  \n",
    "http://books.toscrape.com/index.html  \n",
    "まずは、サイトにアクセスをして、どのような構造になっているのかを把握しましょう。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  必要ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTMLデータの取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTMLデータはrequestモジュールを用いることによって、得ることができます。  \n",
    "requestモジュール自体はhttp通信用に作成されたライブラリです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://books.toscrape.com/index.html\"\n",
    "\n",
    "# Write Me\n",
    "res = requests.get(url)\n",
    "html = res.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoupを用いたHTMLの解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# htmlをBeautifulSoupに代入し、パースを実行します\n",
    "# Write Me\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articleタグの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findl関数によって、articleタグを一件取得してください\n",
    "# Write Me\n",
    "article_tag = soup.find(\"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all関数によって、articleタグを全て取得してください\n",
    "# Write Me\n",
    "article_tags = soup.find_all(\"article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タイトルと画像の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先頭のarticle_tagに対して、タイトルを取得してください\n",
    "# Write Me\n",
    "artile_h3_tag = article_tag.find(\"h3\")\n",
    "title = artile_h3_tag.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先頭のarticle_tagに対して、画像のURLを取得してください\n",
    "# Write Me\n",
    "artile_img_tag = article_tag.find(\"img\")\n",
    "img_url = artile_img_tag[\"src\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ページ（http://books.toscrape.com/index.html ）中の全ての画像のURLと、タイトル名を取得してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titlesとimg_urlsにそれぞれの書籍の画像URLと、タイトル名を格納してください\n",
    "# なお、img_urlには、先頭にドメイン名（http://books.toscrape.com）を付け加えて、格納してください\n",
    "# Write Me\n",
    "titles = []\n",
    "img_urls = []\n",
    "domain_name = \"http://books.toscrape.com\"\n",
    "\n",
    "article_tags = soup.find_all(\"article\")\n",
    "for article_tag in article_tags:\n",
    "    artile_h3_tag = article_tag.find(\"h3\")\n",
    "    title = artile_h3_tag.text\n",
    "    \n",
    "    artile_img_tag = article_tag.find(\"img\")\n",
    "    img_url = domain_name + \"/\"+ artile_img_tag[\"src\"]\n",
    "    \n",
    "    titles.append(title)\n",
    "    img_urls.append(img_url)    \n",
    "\n",
    "print(titles)\n",
    "print(img_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webサイト（http://books.toscrape.com ）中に含まれる書籍の、上位5ページまでの画像のURLと、タイトル名を取得してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titlesとimg_urlsにそれぞれの書籍の画像URLと、タイトル名を格納してください\n",
    "# なお、img_urlには、先頭にドメイン名（http://books.toscrape.com）を付け加えて、格納してください\n",
    "# アクセスをする際には、大量にリクエストを送るのを防ぐために、time.sleep(5)によって、5秒間隔でクローリングしてください\n",
    "# Write Me\n",
    "\n",
    "titles = []\n",
    "img_urls = []\n",
    "domain_name = \"http://books.toscrape.com\"\n",
    "\n",
    "for i in range(1, 5):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-%d.html\" % i\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "\n",
    "    article_tags = soup.find_all(\"article\")\n",
    "    for article_tag in article_tags:\n",
    "        artile_h3_tag = article_tag.find(\"h3\")\n",
    "        title = artile_h3_tag.text\n",
    "\n",
    "        artile_img_tag = article_tag.find(\"img\")\n",
    "        img_url = domain_name + \"/\"+ artile_img_tag[\"src\"]\n",
    "\n",
    "        titles.append(title)\n",
    "        img_urls.append(img_url)    \n",
    "    \n",
    "    time.sleep(5)        \n",
    "\n",
    "print(titles)\n",
    "print(img_urls)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "v8VI5h1izVD7",
    "9fB72RFdzVED",
    "XpMT-H4-zVEJ",
    "1RsZbLnezVEb",
    "_vC1b19zzVEe",
    "qBlrnr4ZzVEg",
    "6JhIursOzVEj",
    "a1VF7sVGzVEm",
    "aVeIzumizVEr",
    "-leR2UY4zVEw",
    "xZeCL0QMzVE4"
   ],
   "default_view": {},
   "name": "excercise.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
